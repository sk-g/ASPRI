{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence to Vector\n",
    "Currently we have the data preprocessed as follows:\n",
    "\n",
    "\n",
    "|  Valid  |  Prefix  | Next Hop  | Path  | Protocol  | Anomaly  |\n",
    "|---|---|---|---|---|\n",
    "| binary  |string   |  string | string  | binary(string)  | binary\n",
    "\n",
    "\n",
    "\n",
    "### Needed soon\n",
    "Need to form sentences first in pure form : prefix, next hop, path.\n",
    "Create a seperate table/data frame in this format:\n",
    "\n",
    "\n",
    "|  Valid  |  sentence  | Anomaly  |\n",
    "|---|---|---|---|---|\n",
    "| binary  |  string    | binary   |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import collections\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "from tempfile import gettempdir\n",
    "import zipfile\n",
    "\n",
    "import numpy as np\n",
    "from six.moves import urllib\n",
    "from six.moves import xrange  # pylint: disable=redefined-builtin\n",
    "import tensorflow as tf\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "# Step 1: Download the data.\n",
    "os.chdir(r'M:\\Course stuff\\ASPRI\\data\\PCH\\paths')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['11012018.txt',\n",
       " '11012018.txt_f.txt',\n",
       " '11012018_f.txt',\n",
       " '24012018.txt',\n",
       " '24012018.txt_f.txt',\n",
       " '24012018_f.txt',\n",
       " 'ReadMe',\n",
       " 'route-collector.vie.pch.net-ipv4_bgp_routes.2018.01.11.txt',\n",
       " 'route-collector.vie.pch.net-ipv4_bgp_routes.2018.01.24.txt',\n",
       " 'table_to_paths.py']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('11012018.txt')\n",
    "vocabulary = f.readlines()\n",
    "vocabulary = [i.strip() for i in vocabulary]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24616, 926786)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = []\n",
    "for i in range(len(vocabulary)):\n",
    "    splits = vocabulary[i].split(' ')\n",
    "    for j in range(len(splits)):\n",
    "        tokens.append(splits[j])\n",
    "unique_tokens = set(tokens)\n",
    "vocabulary_size = len(unique_tokens)\n",
    "len(unique_tokens),len(tokens) # unique ASes, total ASes in all paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(246330, 36868)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary),len(list(set(vocabulary))) # total paths, unique paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(words, n_words):\n",
    "    \"\"\"Process raw inputs into a dataset.\"\"\"\n",
    "    count = [['UNK', -1]]\n",
    "    #count = [[]]\n",
    "    count.extend(collections.Counter(words).most_common(n_words - 1))\n",
    "    dictionary = dict()\n",
    "    #print(count)\n",
    "    for word, _ in count:\n",
    "        dictionary[word] = len(dictionary)\n",
    "    data = list()\n",
    "    unk_count = 0\n",
    "    for word in words:\n",
    "        index = dictionary.get(word, 0)\n",
    "        #print(word,index)\n",
    "        if index == 0:  # dictionary['UNK']\n",
    "            unk_count += 1\n",
    "        data.append(index)\n",
    "    count[0][1] = unk_count\n",
    "    reversed_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n",
    "    return data, count, dictionary, reversed_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common words (+UNK) [['UNK', 0], ('6939', 107961), ('9002', 28904), ('6830', 21032), ('7545', 14248)]\n",
      "Least common words (+UNK) [('38822', 1), ('56206', 1), ('9635', 1), ('55382', 1), ('132281', 1)]\n",
      "Sample data [1, 21, 1760, 6024, 1, 21, 1760, 6024, 1, 21] ['6939', '4826', '38803', '56203', '6939', '4826', '38803', '56203', '6939', '4826']\n"
     ]
    }
   ],
   "source": [
    "# Filling 4 global variables:\n",
    "# data - list of codes (integers from 0 to vocabulary_size-1).\n",
    "#   This is the original text but words are replaced by their codes\n",
    "# count - map of words(strings) to count of occurrences\n",
    "# dictionary - map of words(strings) to their codes(integers)\n",
    "# reverse_dictionary - maps codes(integers) to words(strings)\n",
    "data, count, dictionary, reverse_dictionary = build_dataset(tokens,len(tokens))#vocabulary,vocabulary_size)\n",
    "#del vocabulary  # Hint to reduce memory.\n",
    "print('Most common words (+UNK)', count[:5])\n",
    "print('Least common words (+UNK)',count[-5:])\n",
    "print('Sample data', data[:10], [reverse_dictionary[i] for i in data[:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "926786"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data) #same as total ASes in paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24617"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(count) #unique +1 for UNK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24617, 24617)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dictionary), len(reverse_dictionary) #same size, maps every AS to uniue id == len(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_index = 0\n",
    "\n",
    "# Step 3: Function to generate a training batch for the skip-gram model.\n",
    "def generate_batch(batch_size, num_skips, skip_window):\n",
    "    global data_index\n",
    "    assert batch_size % num_skips == 0\n",
    "    assert num_skips <= 2 * skip_window\n",
    "    batch = np.ndarray(shape=(batch_size), dtype=np.int32)\n",
    "    labels = np.ndarray(shape=(batch_size, 1), dtype=np.int32)\n",
    "    span = 2 * skip_window + 1  # [ skip_window target skip_window ]\n",
    "    buffer = collections.deque(maxlen=span)\n",
    "    if data_index + span > len(data):\n",
    "        data_index = 0\n",
    "    buffer.extend(data[data_index:data_index + span])\n",
    "    data_index += span\n",
    "    for i in range(batch_size // num_skips):\n",
    "        context_words = [w for w in range(span) if w != skip_window]\n",
    "        words_to_use = random.sample(context_words, num_skips)\n",
    "        for j, context_word in enumerate(words_to_use):\n",
    "            batch[i * num_skips + j] = buffer[skip_window]\n",
    "            labels[i * num_skips + j, 0] = buffer[context_word]\n",
    "        if data_index == len(data):\n",
    "            #buffer[:] = data[:span]\n",
    "            for word in data[:span]:\n",
    "                buffer.append(word)\n",
    "            data_index = span\n",
    "        else:\n",
    "            buffer.append(data[data_index])\n",
    "            data_index += 1\n",
    "    # Backtrack a little bit to avoid skipping words in the end of a batch\n",
    "    data_index = (data_index + len(data) - span) % len(data)\n",
    "    return batch, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1760 38803 -> 1 6939\n",
      "1760 38803 -> 1 6939\n",
      "6024 56203 -> 1 6939\n",
      "6024 56203 -> 21 4826\n",
      "1 6939 -> 1760 38803\n",
      "1 6939 -> 21 4826\n",
      "21 4826 -> 1 6939\n",
      "21 4826 -> 1760 38803\n",
      "1760 38803 -> 21 4826\n",
      "1760 38803 -> 1 6939\n",
      "6024 56203 -> 21 4826\n",
      "6024 56203 -> 21 4826\n",
      "1 6939 -> 1760 38803\n",
      "1 6939 -> 1760 38803\n",
      "21 4826 -> 6024 56203\n",
      "21 4826 -> 1 6939\n"
     ]
    }
   ],
   "source": [
    "batch, labels = generate_batch(batch_size=16, num_skips=2, skip_window=2)\n",
    "for i in range(16):\n",
    "    print(batch[i], reverse_dictionary[batch[i]],\n",
    "                '->', labels[i, 0], reverse_dictionary[labels[i, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10026'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverse_dictionary[29]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Build and train a skip-gram model.\n",
    "\n",
    "batch_size = 256\n",
    "embedding_size = 32  # Dimension of the embedding vector.\n",
    "skip_window = 2       # How many words to consider left and right.\n",
    "num_skips = 2         # How many times to reuse an input to generate a label.\n",
    "num_sampled = 64      # Number of negative examples to sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We pick a random validation set to sample nearest neighbors. Here we limit the\n",
    "# validation samples to the words that have a low numeric ID, which by\n",
    "# construction are also the most frequent. These 3 variables are used only for\n",
    "# displaying model accuracy, they don't affect calculation.\n",
    "valid_size = 16     # Random set of words to evaluate similarity on.\n",
    "valid_window = 100  # Only pick dev samples in the head of the distribution.\n",
    "valid_examples = np.random.choice(valid_window, valid_size, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "\n",
    "    # Input data.\n",
    "    train_inputs = tf.placeholder(tf.int32, shape=[batch_size])\n",
    "    train_labels = tf.placeholder(tf.int32, shape=[batch_size, 1])\n",
    "    valid_dataset = tf.constant(valid_examples, dtype=tf.int32)\n",
    "\n",
    "    # Ops and variables pinned to the CPU because of missing GPU implementation\n",
    "    with tf.device('/gpu:0'):\n",
    "        # Look up embeddings for inputs.\n",
    "        embeddings = tf.Variable(\n",
    "                tf.random_uniform([vocabulary_size, embedding_size], -1.0, 1.0))\n",
    "        embed = tf.nn.embedding_lookup(embeddings, train_inputs)\n",
    "\n",
    "        # Construct the variables for the NCE loss\n",
    "        nce_weights = tf.Variable(\n",
    "                tf.truncated_normal([vocabulary_size, embedding_size],\n",
    "                                                        stddev=1.0 / math.sqrt(embedding_size)))\n",
    "        nce_biases = tf.Variable(tf.zeros([vocabulary_size]))\n",
    "    \n",
    "    global_step = tf.Variable(0, trainable=False)\n",
    "    starter_learning_rate = 0.009\n",
    "    learning_rate = tf.train.natural_exp_decay(starter_learning_rate, global_step,2500, 0.56, staircase=False)\n",
    "    # Passing global_step to minimize() will increment it at each step.\n",
    "    #learning_step = (tf.train.GradientDescentOptimizer(learning_rate).minimize(...my loss..., global_step=global_step))\n",
    "    # Compute the average NCE loss for the batch.\n",
    "    # tf.nce_loss automatically draws a new sample of the negative labels each\n",
    "    # time we evaluate the loss.\n",
    "    # Explanation of the meaning of NCE loss:\n",
    "    #   http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/\n",
    "    loss = tf.reduce_mean(\n",
    "            tf.nn.nce_loss(weights=nce_weights,\n",
    "                                         biases=nce_biases,\n",
    "                                         labels=train_labels,\n",
    "                                         inputs=embed,\n",
    "                                         num_sampled=num_sampled,\n",
    "                                         num_classes=vocabulary_size))\n",
    "\n",
    "    # Construct the SGD optimizer using a learning rate of 1.0.\n",
    "    #optimizer = tf.train.GradientDescentOptimizer(1.0).minimize(loss)\n",
    "\n",
    "    # What if we use AdamOptimizer\n",
    "    optimizer = (tf.train.AdamOptimizer(learning_rate).minimize(loss,global_step = global_step))\n",
    "    \n",
    "    # Compute the cosine similarity between minibatch examples and all embeddings.\n",
    "    norm = tf.sqrt(tf.reduce_sum(tf.square(embeddings),\n",
    "     1, keepdims=True)) #keep_dims is deprecated use keepdims instead\n",
    "    normalized_embeddings = embeddings / norm\n",
    "    valid_embeddings = tf.nn.embedding_lookup(\n",
    "            normalized_embeddings, valid_dataset)\n",
    "    similarity = tf.matmul(\n",
    "            valid_embeddings, normalized_embeddings, transpose_b=True)\n",
    "    lr_print = tf.Print(learning_rate,[learning_rate])\n",
    "    # Add variable initializer.\n",
    "    init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Begin training.\n",
    "num_steps = 20001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Average loss at step  0 :  252.064697265625 learning rate:  0.009\n",
      "Average loss at step  250 :  228.3384051513672 learning rate:  0.008509852\n",
      "Average loss at step  500 :  169.77141720581054 learning rate:  0.008046398\n",
      "Average loss at step  750 :  159.86314419555663 learning rate:  0.0076081837\n",
      "Average loss at step  1000 :  125.26792109680176 learning rate:  0.007193836\n",
      "Average loss at step  1250 :  118.27906364440918 learning rate:  0.006802053\n",
      "Average loss at step  1500 :  97.93184477233886 learning rate:  0.0064316075\n",
      "Average loss at step  1750 :  106.1583726348877 learning rate:  0.0060813366\n",
      "Average loss at step  2000 :  98.81370176696777 learning rate:  0.005750142\n",
      "Average loss at step  2250 :  78.91350198364258 learning rate:  0.005436984\n",
      "Average loss at step  2500 :  66.02452368164063 learning rate:  0.0051408815\n",
      "Average loss at step  2750 :  79.82804012298584 learning rate:  0.0048609045\n",
      "Average loss at step  3000 :  78.59286647796631 learning rate:  0.0045961756\n",
      "Average loss at step  3250 :  77.92294459533692 learning rate:  0.004345864\n",
      "Average loss at step  3500 :  64.27094542694091 learning rate:  0.0041091843\n",
      "Average loss at step  3750 :  51.55477652168274 learning rate:  0.0038853942\n",
      "Average loss at step  4000 :  54.15855713272095 learning rate:  0.0036737926\n",
      "Average loss at step  4250 :  50.75746192169189 learning rate:  0.0034737145\n",
      "Average loss at step  4500 :  50.730404312133786 learning rate:  0.003284533\n",
      "Average loss at step  4750 :  42.69477321434021 learning rate:  0.0031056546\n",
      "Average loss at step  5000 :  50.08416749763489 learning rate:  0.002936518\n",
      "Average loss at step  5250 :  39.49082749557495 learning rate:  0.0027765925\n",
      "Average loss at step  5500 :  43.65937704849243 learning rate:  0.002625377\n",
      "Average loss at step  5750 :  42.53729926109314 learning rate:  0.002482397\n",
      "Average loss at step  6000 :  43.01277674007416 learning rate:  0.0023472034\n",
      "Average loss at step  6250 :  39.83401376390457 learning rate:  0.0022193727\n",
      "Average loss at step  6500 :  52.5607453918457 learning rate:  0.0020985038\n",
      "Average loss at step  6750 :  51.600747049331666 learning rate:  0.001984217\n",
      "Average loss at step  7000 :  34.779515842437746 learning rate:  0.0018761551\n",
      "Average loss at step  7250 :  40.57120212364197 learning rate:  0.0017739781\n",
      "Average loss at step  7500 :  27.206536103248595 learning rate:  0.0016773655\n",
      "Average loss at step  7750 :  24.98545991230011 learning rate:  0.001586015\n",
      "Average loss at step  8000 :  31.780770238876343 learning rate:  0.0014996392\n",
      "Average loss at step  8250 :  28.138208660125734 learning rate:  0.0014179676\n",
      "Average loss at step  8500 :  26.842208521842956 learning rate:  0.0013407439\n",
      "Average loss at step  8750 :  23.254334201812743 learning rate:  0.0012677258\n",
      "Average loss at step  9000 :  29.72139929962158 learning rate:  0.0011986842\n",
      "Average loss at step  9250 :  31.310050832748413 learning rate:  0.0011334032\n",
      "Average loss at step  9500 :  26.301264812469483 learning rate:  0.0010716767\n",
      "Average loss at step  9750 :  20.186607941627503 learning rate:  0.0010133124\n",
      "Average loss at step  10000 :  30.365113243579863 learning rate:  0.00095812645\n",
      "Average loss at step  10250 :  31.95533317756653 learning rate:  0.0009059461\n",
      "Average loss at step  10500 :  34.40760461616516 learning rate:  0.0008566075\n",
      "Average loss at step  10750 :  27.059411951065062 learning rate:  0.00080995617\n",
      "Average loss at step  11000 :  21.669397698402406 learning rate:  0.000765845\n",
      "Average loss at step  11250 :  25.142310390472414 learning rate:  0.0007241365\n",
      "Average loss at step  11500 :  22.29601929664612 learning rate:  0.00068469933\n",
      "Average loss at step  11750 :  24.50142666912079 learning rate:  0.00064741005\n",
      "Average loss at step  12000 :  20.49760166978836 learning rate:  0.0006121516\n",
      "Average loss at step  12250 :  26.448137129783632 learning rate:  0.00057881325\n",
      "Average loss at step  12500 :  20.190034750461578 learning rate:  0.00054729055\n",
      "Average loss at step  12750 :  24.35439097595215 learning rate:  0.0005174846\n",
      "Average loss at step  13000 :  24.57429624223709 learning rate:  0.000489302\n",
      "Average loss at step  13250 :  26.19165488576889 learning rate:  0.0004626542\n",
      "Average loss at step  13500 :  25.042952913284303 learning rate:  0.00043745755\n",
      "Average loss at step  13750 :  36.84075710868836 learning rate:  0.00041363333\n",
      "Average loss at step  14000 :  34.603559844970704 learning rate:  0.00039110647\n",
      "Average loss at step  14250 :  23.17282420063019 learning rate:  0.0003698065\n",
      "Average loss at step  14500 :  27.652835057258606 learning rate:  0.00034966654\n",
      "Average loss at step  14750 :  17.70226150894165 learning rate:  0.00033062336\n",
      "Average loss at step  15000 :  17.408294805049895 learning rate:  0.00031261728\n",
      "Average loss at step  15250 :  22.00105736064911 learning rate:  0.00029559192\n",
      "Average loss at step  15500 :  20.800077149391175 learning rate:  0.00027949375\n",
      "Average loss at step  15750 :  18.41417375802994 learning rate:  0.00026427227\n",
      "Average loss at step  16000 :  15.209144651412965 learning rate:  0.00024987978\n",
      "Average loss at step  16250 :  23.30276240634918 learning rate:  0.00023627105\n",
      "Average loss at step  16500 :  25.096206743240355 learning rate:  0.00022340358\n",
      "Average loss at step  16750 :  19.678930218696593 learning rate:  0.00021123684\n",
      "Average loss at step  17000 :  15.352335790634156 learning rate:  0.00019973269\n",
      "Average loss at step  17250 :  24.795196194648742 learning rate:  0.00018885508\n",
      "Average loss at step  17500 :  26.36465311527252 learning rate:  0.00017856981\n",
      "Average loss at step  17750 :  29.224769128799437 learning rate:  0.00016884477\n",
      "Average loss at step  18000 :  22.126599098205567 learning rate:  0.00015964934\n",
      "Average loss at step  18250 :  18.147256240844726 learning rate:  0.00015095473\n",
      "Average loss at step  18500 :  20.443564868927 learning rate:  0.00014273364\n",
      "Average loss at step  18750 :  18.69297586584091 learning rate:  0.00013496022\n",
      "Average loss at step  19000 :  20.831004867553713 learning rate:  0.00012761012\n",
      "Average loss at step  19250 :  18.73097984981537 learning rate:  0.0001206604\n",
      "Average loss at step  19500 :  22.901879086494446 learning rate:  0.00011408911\n",
      "Average loss at step  19750 :  16.556771832942964 learning rate:  0.00010787574\n",
      "Average loss at step  20000 :  21.98641973209381 learning rate:  0.00010200071\n",
      "Time Taken: 322.29864478111267\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import time\n",
    "start = time.time()\n",
    "with tf.Session(graph=graph) as session:\n",
    "    # We must initialize all variables before we use them.\n",
    "    init.run()\n",
    "    print('Initialized')\n",
    "\n",
    "    average_loss = 0\n",
    "    for step in xrange(num_steps):\n",
    "        batch_inputs, batch_labels = generate_batch(\n",
    "                batch_size, num_skips, skip_window)\n",
    "        feed_dict = {train_inputs: batch_inputs, train_labels: batch_labels}\n",
    "\n",
    "        # We perform one update step by evaluating the optimizer op (including it\n",
    "        # in the list of returned values for session.run()\n",
    "        _, loss_val,__ = session.run([optimizer, loss,lr_print], feed_dict=feed_dict)\n",
    "        average_loss += loss_val\n",
    "        if step % 250 == 0:\n",
    "            if step > 0:\n",
    "                average_loss /= 250\n",
    "            # The average loss is an estimate of the loss over the last 2000 batches.\n",
    "            print('Average loss at step ', step, ': ', average_loss,'learning rate: ',__)\n",
    "            average_loss = 0\n",
    "    final_embeddings = normalized_embeddings.eval()\n",
    "end = time.time()\n",
    "print(\"Time Taken: {}\".format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24616, 32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2v = vocabulary.copy()\n",
    "for i in range(len(vocabulary)):\n",
    "    splits = vocabulary[i].split(' ')\n",
    "    splits2 = splits\n",
    "    t= []\n",
    "    for j in range(len(splits)):\n",
    "        #print(type(j))\n",
    "        splits2[j]= final_embeddings[dictionary[splits[j]]-1]\n",
    "    s2v[i] = splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_tokens = list(set(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_dict = {}\n",
    "bigrams = [b for l in vocabulary for b in zip(l.split(' ')[:-1],l.split(' ')[1:])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(bigrams)):\n",
    "    a,b = bigrams[i][0],bigrams[i][1]\n",
    "    bigram_dict[bigrams[i]] = np.dot(final_embeddings[dictionary[a]-1],final_embeddings[dictionary[b]-1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_ngrams(strx,n):\n",
    "    return list(zip(*[strx.split(' ')[i:] for i in range(n)]))\n",
    "t = find_ngrams(vocabulary[0],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('6939 4826 38803 56203',\n",
       " [('6939', '4826'), ('4826', '38803'), ('38803', '56203')])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary[0],(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_s = 0\n",
    "for i in t:\n",
    "    r_s += bigram_dict[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3489672839641571"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sbs(arr): #sum of bigrams in each sentence\n",
    "    sbs = []\n",
    "    for i in range(len(arr)):\n",
    "        t = list(find_ngrams(vocabulary[i],2))\n",
    "        t = [bigram_dict[i] for i in t]\n",
    "        sbs.append(sum(t))\n",
    "    return sbs\n",
    "array_of_bigram_sums = sbs(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_sum = sum(array_of_bigram_sums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "433846.876114944"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7612425450206795"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg = total_sum/len(vocabulary)\n",
    "avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5612563937902451, 27.71648621559143)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(array_of_bigram_sums),max(array_of_bigram_sums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1347853364292146"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(array_of_bigram_sums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.8532e+05, 4.3210e+04, 1.1427e+04, 4.1580e+03, 1.7970e+03,\n",
       "        1.5600e+02, 1.7600e+02, 7.3000e+01, 6.0000e+00, 7.0000e+00]),\n",
       " array([-0.56125639,  2.26651787,  5.09429213,  7.92206639, 10.74984065,\n",
       "        13.57761491, 16.40538917, 19.23316343, 22.06093769, 24.88871195,\n",
       "        27.71648622]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x208337c1d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(array_of_bigram_sums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2083bc9f0b8>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20918be4438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(array_of_bigram_sums[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x209071924e0>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2090dec80f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(array_of_bigram_sums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModeResult(mode=array([0.]), count=array([9272]))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "stats.mode(array_of_bigram_sums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_path = \"6939 4826 4770 4770 4770 4770 4770 4770 24074 4651\"\n",
    "rpb = find_ngrams(random_path,2)\n",
    "arr = sbs(rpb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.588510937988758"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('6939', '4826'),\n",
       " ('4826', '4770'),\n",
       " ('4770', '4770'),\n",
       " ('4770', '4770'),\n",
       " ('4770', '4770'),\n",
       " ('4770', '4770'),\n",
       " ('4770', '4770'),\n",
       " ('4770', '24074'),\n",
       " ('24074', '4651')]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rpb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99999994"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_dict[('4770','4770')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21759763"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_dict[('6939','4826')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0712905"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(final_embeddings[dictionary['6939']],final_embeddings[dictionary['24074']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.422816"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(final_embeddings[dictionary['4770']],final_embeddings[dictionary['6939']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
