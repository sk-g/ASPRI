save_path       models/ptb/ptb_wordchar9-invert_discourse/
data_path       data/PennTreeBank
vocab_size      10000
vocab           False
layer           LSTM
num_layers      1
size    `       512
num_steps       35
init_scale      0.05
learning_rate   1       
max_grad_norm   5
batch_size      20
forget_bias     0
dropout         0.5
max_epoch       6
max_max_epoch   39
lr_decay        0.8
optimizer       sgd
trainer         trainer
softmax         full
word_char_concat        True
char_size       10
num_char        9
order           end_first
