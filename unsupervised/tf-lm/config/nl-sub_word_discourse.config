save_path       models/sub/sub_word_discourse/
data_path       data/STON
encoding        latin-1
vocab_size      100000
vocab           100
layer           LSTM
num_layers      2
size    `       512
num_steps       35
init_scale      0.05
learning_rate   1       
max_grad_norm   5
batch_size      20
forget_bias     0
dropout         0.5
max_epoch       2
max_max_epoch   39
lr_decay        0.8
optimizer       sgd
trainer         earlyStopping
softmax         sampled
early_stop      2
