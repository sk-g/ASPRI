{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import os,re,time,sys,os,math,random,time,pickle\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM,Flatten,Dense,Embedding\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split as split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(r'M:\\Course stuff\\ASPRI\\data\\PCH\\paths\\11012018.txt','r')\n",
    "lines = f.readlines()\n",
    "lines = [i.strip() for i in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'dict'> <class 'dict'> <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "final_embeddings = pickle.load(open(r'M:\\Course stuff\\ASPRI\\supervised\\loal_FE','rb'))\n",
    "dictionary = pickle.load(open(r'M:\\Course stuff\\ASPRI\\supervised\\dictionary','rb'))\n",
    "reverse_dictionary = pickle.load(open(r'M:\\Course stuff\\ASPRI\\supervised\\reverse_dictionary','rb'))\n",
    "count = pickle.load(open(r'M:\\Course stuff\\ASPRI\\supervised\\count','rb'))\n",
    "print(type(final_embeddings),type(dictionary),type(reverse_dictionary),type(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nd_array = []\n",
    "for i in range(30):\n",
    "    nd_array.append(np.zeros(shape = (32,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nd_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_array = []\n",
    "for i in range(len(lines)):\n",
    "    new_array.append(nd_array)\n",
    "new_array = np.asarray(new_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(lines)):\n",
    "    splits = lines[i].split(' ')\n",
    "    for j in range(len(splits)):\n",
    "        #print(new_array[i][j])\n",
    "        new_array[i,j] = final_embeddings[dictionary[str(splits[j])]-1].reshape(32,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_array[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paths</th>\n",
       "      <th>Fake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6939 4826 38803 56203</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6939 4826 38803 56203</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6939 4826 38803 56203</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6939 4826 38803 56203</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6939 4826 38803 56203</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Paths  Fake\n",
       "0  6939 4826 38803 56203   0.0\n",
       "1  6939 4826 38803 56203   0.0\n",
       "2  6939 4826 38803 56203   0.0\n",
       "3  6939 4826 38803 56203   0.0\n",
       "4  6939 4826 38803 56203   0.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if os.name != 'posix':\n",
    "    paths = pd.read_csv(r'M:\\Course stuff\\ASPRI\\supervised\\11012018.csv',sep='\\t',low_memory = False,index_col = False)\n",
    "else:\n",
    "    paths = pd.read_csv('11012018.csv',sep='\\t',low_memory = False,index_col = False)\n",
    "    del paths['Unnamed: 0']\n",
    "paths.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test = split(paths,test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x229781f61d0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x229784ad048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x = 'Fake',data = train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    172272\n",
       "1.0     46684\n",
       "Name: Fake, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.Fake.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    74058\n",
       "1.0    19781\n",
       "Name: Fake, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.Fake.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 30\n",
    "vocab_size = 24612 #unique tokens for this file\n",
    "#encoded_train = [one_hot(d,vocab_size) for d in train['Paths']]\n",
    "#encoded_test = [one_hot(d,vocab_size) for d in test['Paths']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_lines(arr):\n",
    "    # function works on df\n",
    "    # iterate over lines in df\n",
    "    # iterate over splits of line\n",
    "    # convert split word to embedding vector (32,1)\n",
    "    # pad with (32,1) zeros\n",
    "    \n",
    "    \n",
    "    new_array = []\n",
    "    for i in range(len(arr)):\n",
    "        new_array.append(nd_array)\n",
    "    new_array = np.asarray(new_array)\n",
    "    c = 0\n",
    "    for i in arr['Paths']:\n",
    "        splits = i.split(' ')\n",
    "        for j in range(len(splits)):\n",
    "            #print(new_array[i][j])\n",
    "            new_array[c,j] = final_embeddings[dictionary[str(splits[j])]-1].reshape(32,1)\n",
    "        c += 1\n",
    "    assert(len(new_array) == len(arr))\n",
    "    assert(len(new_array[0]) == 30)\n",
    "    return new_array\n",
    "encoded_train = encode_lines(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "218956"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoded_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_test = encode_lines(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lengths = [len(t) for t in encoded_train] #array of lengths so we can pad zeros later\n",
    "test_lengths= [len(t) for t in encoded_test] #array of lengths for test set to be padded later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test,y_train = test['Fake'],train['Fake']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = encode_lines(train)#['Paths'])\n",
    "x_test = encode_lines(test)#['Paths'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 30\n",
    "vocab_size = 24612 #unique tokens for this file\n",
    "encoded_train = [one_hot(d,vocab_size) for d in train['Paths']]\n",
    "encoded_test = [one_hot(d,vocab_size) for d in test['Paths']]\n",
    "train_lengths = [len(t) for t in encoded_train] #array of lengths so we can pad zeros later\n",
    "test_lengths= [len(t) for t in encoded_test] #array of lengths for test set to be padded later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train = train['Fake']\n",
    "train_dic={}\n",
    "train_dic[\"data\"] = encoded_train\n",
    "train_dic[\"labels\"] = labels_train#labels_train[0].ravel().tolist()\n",
    "train_dic[\"length\"] = train_lengths\n",
    "train_len = len(train)\n",
    "test_len = len(test)\n",
    "\n",
    "train_ = pd.DataFrame.from_dict(data=train_dic, orient='columns', dtype=None)\n",
    "\n",
    "\n",
    "\n",
    "test_dic={}\n",
    "test_dic[\"data\"] = encoded_test\n",
    "test_dic[\"length\"] = test_lengths\n",
    "test_dic[\"labels\"] = test['Fake']\n",
    "test_ = pd.DataFrame.from_dict(data=test_dic, orient='columns', dtype=None)\n",
    "\n",
    "test_input = test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test = train_[\"data\"],test_[\"data\"]\n",
    "y_train,y_test = train['Fake'],test['Fake']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218956 train sequences\n",
      "93839 test sequences\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (218956, 30)\n",
      "x_test shape: (93839, 30)\n"
     ]
    }
   ],
   "source": [
    "max_features = vocab_size\n",
    "maxlen = 30  # cut texts after this number of words (among top max_features most common words)\n",
    "batch_size = 256\n",
    "#x_train,\n",
    "#print('Loading data...')\n",
    "#(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 218956 samples, validate on 93839 samples\n",
      "Epoch 1/15\n",
      "218956/218956 [==============================] - 170s - loss: 0.3057 - acc: 0.8861 - val_loss: 0.2108 - val_acc: 0.9328\n",
      "Epoch 2/15\n",
      "218956/218956 [==============================] - 166s - loss: 0.1898 - acc: 0.9409 - val_loss: 0.1934 - val_acc: 0.9399\n",
      "Epoch 3/15\n",
      "218956/218956 [==============================] - 166s - loss: 0.1718 - acc: 0.9465 - val_loss: 0.1912 - val_acc: 0.9421\n",
      "Epoch 4/15\n",
      "218956/218956 [==============================] - 166s - loss: 0.1630 - acc: 0.9488 - val_loss: 0.1931 - val_acc: 0.9428\n",
      "Epoch 5/15\n",
      "218956/218956 [==============================] - 166s - loss: 0.1568 - acc: 0.9504 - val_loss: 0.1945 - val_acc: 0.9437\n",
      "Epoch 6/15\n",
      "218956/218956 [==============================] - 167s - loss: 0.1524 - acc: 0.9519 - val_loss: 0.1943 - val_acc: 0.9450\n",
      "Epoch 7/15\n",
      "218956/218956 [==============================] - 167s - loss: 0.1489 - acc: 0.9524 - val_loss: 0.1986 - val_acc: 0.9451\n",
      "Epoch 8/15\n",
      "218956/218956 [==============================] - 167s - loss: 0.1481 - acc: 0.9527 - val_loss: 0.1976 - val_acc: 0.9448\n",
      "Epoch 9/15\n",
      "218956/218956 [==============================] - 167s - loss: 0.1459 - acc: 0.9533 - val_loss: 0.1998 - val_acc: 0.9463\n",
      "Epoch 10/15\n",
      "218956/218956 [==============================] - 167s - loss: 0.1437 - acc: 0.9540 - val_loss: 0.1998 - val_acc: 0.9469\n",
      "Epoch 11/15\n",
      "218956/218956 [==============================] - 167s - loss: 0.1449 - acc: 0.9531 - val_loss: 0.2238 - val_acc: 0.9323\n",
      "Epoch 12/15\n",
      "218956/218956 [==============================] - 166s - loss: 0.1525 - acc: 0.9512 - val_loss: 0.2012 - val_acc: 0.9461\n",
      "Epoch 13/15\n",
      "218956/218956 [==============================] - 167s - loss: 0.1436 - acc: 0.9539 - val_loss: 0.2039 - val_acc: 0.9466\n",
      "Epoch 14/15\n",
      "218956/218956 [==============================] - 167s - loss: 0.1419 - acc: 0.9544 - val_loss: 0.2068 - val_acc: 0.9465\n",
      "Epoch 15/15\n",
      "218956/218956 [==============================] - 166s - loss: 0.1406 - acc: 0.9549 - val_loss: 0.2074 - val_acc: 0.9466\n",
      "93696/93839 [============================>.] - ETA: 0sTest score: 0.20741988153120183\n",
      "Test accuracy: 0.9466426539021426\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=15,\n",
    "          validation_data=(x_test, y_test))\n",
    "score, acc = model.evaluate(x_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Train...\n",
      "Train on 218956 samples, validate on 93839 samples\n",
      "Epoch 1/15\n",
      "218956/218956 [==============================] - 170s - loss: 0.4385 - acc: 0.8327 - val_loss: 0.5994 - val_acc: 0.7122\n",
      "Epoch 2/15\n",
      "218956/218956 [==============================] - 169s - loss: 0.3407 - acc: 0.8926 - val_loss: 0.3034 - val_acc: 0.9115\n",
      "Epoch 3/15\n",
      "218956/218956 [==============================] - 167s - loss: 0.2861 - acc: 0.9166 - val_loss: 0.2733 - val_acc: 0.9210\n",
      "Epoch 4/15\n",
      "218956/218956 [==============================] - 168s - loss: 0.2410 - acc: 0.9295 - val_loss: 0.2784 - val_acc: 0.9243\n",
      "Epoch 5/15\n",
      "218956/218956 [==============================] - 168s - loss: 0.2229 - acc: 0.9339 - val_loss: 0.2829 - val_acc: 0.9278\n",
      "Epoch 6/15\n",
      "218956/218956 [==============================] - 167s - loss: 0.2294 - acc: 0.9317 - val_loss: 0.2601 - val_acc: 0.9277\n",
      "Epoch 7/15\n",
      "218956/218956 [==============================] - 167s - loss: 0.2176 - acc: 0.9360 - val_loss: 0.2841 - val_acc: 0.9258\n",
      "Epoch 8/15\n",
      "218956/218956 [==============================] - 171s - loss: 0.2054 - acc: 0.9375 - val_loss: 0.2988 - val_acc: 0.9307\n",
      "Epoch 9/15\n",
      "218956/218956 [==============================] - 169s - loss: 0.1966 - acc: 0.9390 - val_loss: 0.2966 - val_acc: 0.9286\n",
      "Epoch 10/15\n",
      "218956/218956 [==============================] - 168s - loss: 0.1928 - acc: 0.9397 - val_loss: 0.3001 - val_acc: 0.9302\n",
      "Epoch 11/15\n",
      "218956/218956 [==============================] - 168s - loss: 0.1930 - acc: 0.9395 - val_loss: 0.3045 - val_acc: 0.9257\n",
      "Epoch 12/15\n",
      "218956/218956 [==============================] - 168s - loss: 0.1874 - acc: 0.9374 - val_loss: 0.3020 - val_acc: 0.9250\n",
      "Epoch 13/15\n",
      "218956/218956 [==============================] - 168s - loss: 0.1865 - acc: 0.9368 - val_loss: 0.2613 - val_acc: 0.9306\n",
      "Epoch 14/15\n",
      "218956/218956 [==============================] - 174s - loss: 0.1922 - acc: 0.9332 - val_loss: 0.2943 - val_acc: 0.9286\n",
      "Epoch 15/15\n",
      "218956/218956 [==============================] - 168s - loss: 0.1831 - acc: 0.9345 - val_loss: 0.3040 - val_acc: 0.9279\n",
      "93696/93839 [============================>.] - ETA: 0sTest score: 0.3040339263687087\n",
      "Test accuracy: 0.9278871257774238\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='tanh'))\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=15,\n",
    "          validation_data=(x_test, y_test))\n",
    "score, acc = model.evaluate(x_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=15,\n",
    "          validation_data=(x_test, y_test))\n",
    "score, acc = model.evaluate(x_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='elu'))\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=15,\n",
    "          validation_data=(x_test, y_test))\n",
    "score, acc = model.evaluate(x_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
