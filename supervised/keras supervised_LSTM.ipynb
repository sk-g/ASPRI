{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import os,re,time,sys,os,math,random,time,pickle,keras,graphviz\n",
    "import pydot_ng as pydot\n",
    "import pydot\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM,Flatten,Dense,Embedding\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pylab as pl\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split as split\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.name != 'posix':\n",
    "    f = open(r'M:\\Course stuff\\ASPRI\\data\\PCH\\paths\\11012018.txt','r')\n",
    "else:\n",
    "    f = open('../data/PCH/paths/11012018.txt','r')\n",
    "lines = f.readlines()\n",
    "lines = [i.strip() for i in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'dict'> <class 'dict'> <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "if os.name != 'posix':\n",
    "    final_embeddings = pickle.load(open(r'M:\\Course stuff\\ASPRI\\supervised\\loal_FE','rb'))\n",
    "    dictionary = pickle.load(open(r'M:\\Course stuff\\ASPRI\\supervised\\dictionary','rb'))\n",
    "    reverse_dictionary = pickle.load(open(r'M:\\Course stuff\\ASPRI\\supervised\\reverse_dictionary','rb'))\n",
    "    count = pickle.load(open(r'M:\\Course stuff\\ASPRI\\supervised\\count','rb'))\n",
    "else:\n",
    "    final_embeddings = pickle.load(open('loal_FE','rb'))\n",
    "    dictionary = pickle.load(open('dictionary','rb'))\n",
    "    reverse_dictionary = pickle.load(open('reverse_dictionary','rb'))\n",
    "    count = pickle.load(open('count','rb'))\n",
    "print(type(final_embeddings),type(dictionary),type(reverse_dictionary),type(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nd_array = []\n",
    "for i in range(30):\n",
    "    nd_array.append(np.zeros(shape = (32,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nd_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_array = []\n",
    "for i in range(len(lines)):\n",
    "    new_array.append(nd_array)\n",
    "new_array = np.asarray(new_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(lines)):\n",
    "    splits = lines[i].split(' ')\n",
    "    for j in range(len(splits)):\n",
    "        #print(new_array[i][j])\n",
    "        new_array[i,j] = final_embeddings[dictionary[str(splits[j])]-1].reshape(32,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_array[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Paths</th>\n",
       "      <th>Fake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>6939 4826 38803 56203</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>6939 4826 38803 56203</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>6939 4826 38803 56203</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>6939 4826 38803 56203</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6939 4826 38803 56203</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                  Paths  Fake\n",
       "0           0  6939 4826 38803 56203   0.0\n",
       "1           1  6939 4826 38803 56203   0.0\n",
       "2           2  6939 4826 38803 56203   0.0\n",
       "3           3  6939 4826 38803 56203   0.0\n",
       "4           4  6939 4826 38803 56203   0.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if os.name != 'posix':\n",
    "    paths = pd.read_csv(r'M:\\Course stuff\\ASPRI\\supervised\\11012018.csv',sep='\\t',low_memory = False,index_col = False)\n",
    "else:\n",
    "    paths = pd.read_csv('11012018.csv',sep='\\t',low_memory = False,index_col = False)\n",
    "    del paths['Unnamed: 0']\n",
    "paths.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test = split(paths,test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1900a5b6f60>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1900a519080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x = 'Fake',data = train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    172666\n",
       "1.0     46290\n",
       "Name: Fake, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.Fake.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    73664\n",
       "1.0    20175\n",
       "Name: Fake, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.Fake.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 30\n",
    "vocab_size = 24612 #unique tokens for this file\n",
    "#encoded_train = [one_hot(d,vocab_size) for d in train['Paths']]\n",
    "#encoded_test = [one_hot(d,vocab_size) for d in test['Paths']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_lines(arr):\n",
    "    # function works on df\n",
    "    # iterate over lines in df\n",
    "    # iterate over splits of line\n",
    "    # convert split word to embedding vector (32,1)\n",
    "    # pad with (32,1) zeros\n",
    "    \n",
    "    \n",
    "    new_array = []\n",
    "    for i in range(len(arr)):\n",
    "        new_array.append(nd_array)\n",
    "    new_array = np.asarray(new_array)\n",
    "    c = 0\n",
    "    for i in arr['Paths']:\n",
    "        splits = i.split(' ')\n",
    "        for j in range(len(splits)):\n",
    "            #print(new_array[i][j])\n",
    "            new_array[c,j] = final_embeddings[dictionary[str(splits[j])]-1].reshape(32,1)\n",
    "        c += 1\n",
    "    assert(len(new_array) == len(arr))\n",
    "    assert(len(new_array[0]) == 30)\n",
    "    return new_array\n",
    "encoded_train = encode_lines(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "218956"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoded_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_test = encode_lines(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lengths = [len(t) for t in encoded_train] #array of lengths so we can pad zeros later\n",
    "test_lengths= [len(t) for t in encoded_test] #array of lengths for test set to be padded later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test,y_train = test['Fake'],train['Fake']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = encode_lines(train)#['Paths'])\n",
    "x_test = encode_lines(test)#['Paths'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 30\n",
    "vocab_size = 24612 #unique tokens for this file\n",
    "encoded_train = [one_hot(d,vocab_size) for d in train['Paths']]\n",
    "encoded_test = [one_hot(d,vocab_size) for d in test['Paths']]\n",
    "train_lengths = [len(t) for t in encoded_train] #array of lengths so we can pad zeros later\n",
    "test_lengths= [len(t) for t in encoded_test] #array of lengths for test set to be padded later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train = train['Fake']\n",
    "train_dic={}\n",
    "train_dic[\"data\"] = encoded_train\n",
    "train_dic[\"labels\"] = labels_train#labels_train[0].ravel().tolist()\n",
    "train_dic[\"length\"] = train_lengths\n",
    "train_len = len(train)\n",
    "test_len = len(test)\n",
    "\n",
    "train_ = pd.DataFrame.from_dict(data=train_dic, orient='columns', dtype=None)\n",
    "\n",
    "\n",
    "\n",
    "test_dic={}\n",
    "test_dic[\"data\"] = encoded_test\n",
    "test_dic[\"length\"] = test_lengths\n",
    "test_dic[\"labels\"] = test['Fake']\n",
    "test_ = pd.DataFrame.from_dict(data=test_dic, orient='columns', dtype=None)\n",
    "\n",
    "test_input = test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test = train_[\"data\"],test_[\"data\"]\n",
    "y_train,y_test = train['Fake'],test['Fake']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218956 train sequences\n",
      "93839 test sequences\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (218956, 30)\n",
      "x_test shape: (93839, 30)\n"
     ]
    }
   ],
   "source": [
    "max_features = vocab_size\n",
    "maxlen = 30  # cut texts after this number of words (among top max_features most common words)\n",
    "batch_size = 128\n",
    "epochs = 5 #training steps\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')\n",
    "print('Pad sequences (samples x time)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "WARNING:tensorflow:From c:\\program files\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1188: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From c:\\program files\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1290: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 32)          787584    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 30)                7560      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 795,175\n",
      "Trainable params: 795,175\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 218956 samples, validate on 93839 samples\n",
      "Epoch 1/5\n",
      "218956/218956 [==============================] - 145s - loss: 0.2426 - acc: 0.9218 - val_loss: 0.1476 - val_acc: 0.9605\n",
      "Epoch 2/5\n",
      "218956/218956 [==============================] - 141s - loss: 0.1401 - acc: 0.9623 - val_loss: 0.1414 - val_acc: 0.9624\n",
      "Epoch 3/5\n",
      "218956/218956 [==============================] - 146s - loss: 0.1305 - acc: 0.9641 - val_loss: 0.1452 - val_acc: 0.9621\n",
      "Epoch 4/5\n",
      "218956/218956 [==============================] - 153s - loss: 0.1251 - acc: 0.9648 - val_loss: 0.1481 - val_acc: 0.9621\n",
      "Epoch 5/5\n",
      "218956/218956 [==============================] - 156s - loss: 0.1213 - acc: 0.9651 - val_loss: 0.1531 - val_acc: 0.9622\n",
      "93839/93839 [==============================] - 16s    \n",
      "Test score: 0.15305916457375993\n",
      "Test accuracy: 0.9622225300781125\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 32))\n",
    "model.add(LSTM(30, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "print('Train...')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(x_test, y_test))\n",
    "score_lstm_sigmoid_FC, acc_lstm_sigmoid_FC = model.evaluate(x_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test score:', score_lstm_sigmoid_FC)\n",
    "print('Test accuracy:', acc_lstm_sigmoid_FC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, None, 32)          787584    \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 30)                5670      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 793,285\n",
      "Trainable params: 793,285\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 218956 samples, validate on 93839 samples\n",
      "Epoch 1/5\n",
      "218956/218956 [==============================] - 127s - loss: 0.2178 - acc: 0.9351 - val_loss: 0.1509 - val_acc: 0.9610\n",
      "Epoch 2/5\n",
      "218956/218956 [==============================] - 130s - loss: 0.1403 - acc: 0.9627 - val_loss: 0.1472 - val_acc: 0.9601\n",
      "Epoch 3/5\n",
      "218956/218956 [==============================] - 132s - loss: 0.1306 - acc: 0.9643 - val_loss: 0.1473 - val_acc: 0.9617\n",
      "Epoch 4/5\n",
      "218956/218956 [==============================] - 131s - loss: 0.1255 - acc: 0.9648 - val_loss: 0.1486 - val_acc: 0.9620\n",
      "Epoch 5/5\n",
      "218956/218956 [==============================] - 134s - loss: 0.1218 - acc: 0.9652 - val_loss: 0.1533 - val_acc: 0.9616\n",
      "93568/93839 [============================>.] - ETA: 0sTest score: 0.15329421910085367\n",
      "Test accuracy: 0.9615618239751063\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 32))\n",
    "model.add(keras.layers.GRU(30, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "print('Train...')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(x_test, y_test))\n",
    "score_gru_sigmoid_FC, acc_gru_sigmoid_FC = model.evaluate(x_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test score:', score_gru_sigmoid_FC)\n",
    "print('Test accuracy:', acc_gru_sigmoid_FC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, None, 32)          787584    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 30)                7560      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 795,175\n",
      "Trainable params: 795,175\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 218956 samples, validate on 93839 samples\n",
      "Epoch 1/5\n",
      "218956/218956 [==============================] - 138s - loss: 0.3509 - acc: 0.8794 - val_loss: 0.2650 - val_acc: 0.9057\n",
      "Epoch 2/5\n",
      "218956/218956 [==============================] - 146s - loss: 0.2559 - acc: 0.9278 - val_loss: 0.2475 - val_acc: 0.9395\n",
      "Epoch 3/5\n",
      "218956/218956 [==============================] - 161s - loss: 0.2174 - acc: 0.9444 - val_loss: 0.2051 - val_acc: 0.9494\n",
      "Epoch 4/5\n",
      "218956/218956 [==============================] - 168s - loss: 0.2070 - acc: 0.9461 - val_loss: 0.2165 - val_acc: 0.9483\n",
      "Epoch 5/5\n",
      "218956/218956 [==============================] - 149s - loss: 0.1822 - acc: 0.9530 - val_loss: 0.2278 - val_acc: 0.9530\n",
      "93824/93839 [============================>.] - ETA: 0sTest score: 0.2277915366927691\n",
      "Test accuracy: 0.952983301186074\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 32))\n",
    "model.add(LSTM(30, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='tanh'))\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "print('Train...')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size = batch_size,\n",
    "          epochs = epochs,\n",
    "          validation_data = (x_test, y_test))\n",
    "score_lstm_tanh_FC, acc_lstm_tanh_FC = model.evaluate(x_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test score:', score_lstm_tanh_FC)\n",
    "print('Test accuracy:', acc_lstm_tanh_FC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, None, 32)          787584    \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 30)                7560      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 795,175\n",
      "Trainable params: 795,175\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 218956 samples, validate on 93839 samples\n",
      "Epoch 1/5\n",
      "218956/218956 [==============================] - 147s - loss: 0.3522 - acc: 0.8615 - val_loss: 0.2771 - val_acc: 0.8566\n",
      "Epoch 2/5\n",
      "218956/218956 [==============================] - 143s - loss: 0.2446 - acc: 0.8729 - val_loss: 0.2034 - val_acc: 0.8544\n",
      "Epoch 3/5\n",
      "218956/218956 [==============================] - 144s - loss: 0.1928 - acc: 0.8477 - val_loss: 0.1909 - val_acc: 0.8320\n",
      "Epoch 4/5\n",
      "218956/218956 [==============================] - 144s - loss: 0.1704 - acc: 0.8310 - val_loss: 0.2064 - val_acc: 0.8265\n",
      "Epoch 5/5\n",
      "218956/218956 [==============================] - 143s - loss: 0.1595 - acc: 0.8256 - val_loss: 0.2221 - val_acc: 0.8101\n",
      "93839/93839 [==============================] - 15s    \n",
      "Test score: 0.2220530925511197\n",
      "Test accuracy: 0.810142904338691\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 32))\n",
    "model.add(LSTM(30, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "print('Train...')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(x_test, y_test))\n",
    "score_lstm_relu_FC, acc_lstm_relu_FC = model.evaluate(x_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test score:', score_lstm_relu_FC)\n",
    "print('Test accuracy:', acc_lstm_relu_FC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, None, 32)          787584    \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 30)                7560      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 795,175\n",
      "Trainable params: 795,175\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 218956 samples, validate on 93839 samples\n",
      "Epoch 1/5\n",
      "218956/218956 [==============================] - 146s - loss: 0.3728 - acc: 0.8505 - val_loss: 0.3000 - val_acc: 0.8458\n",
      "Epoch 2/5\n",
      "218956/218956 [==============================] - 144s - loss: 0.2858 - acc: 0.8629 - val_loss: 0.2471 - val_acc: 0.8682\n",
      "Epoch 3/5\n",
      "218956/218956 [==============================] - 145s - loss: 0.2528 - acc: 0.8572 - val_loss: 0.2627 - val_acc: 0.8347\n",
      "Epoch 4/5\n",
      "218956/218956 [==============================] - 144s - loss: 0.2122 - acc: 0.8547 - val_loss: 0.2464 - val_acc: 0.8470\n",
      "Epoch 5/5\n",
      "218956/218956 [==============================] - 143s - loss: 0.1887 - acc: 0.8462 - val_loss: 0.2599 - val_acc: 0.8323\n",
      "93839/93839 [==============================] - 15s    \n",
      "Test score: 0.2599336272873646\n",
      "Test accuracy: 0.8323404980903252\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 32))\n",
    "model.add(LSTM(30, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='elu'))\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "print('Train...')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(x_test, y_test))\n",
    "score_lstm_elu_FC, acc_lstm_elu_FC = model.evaluate(x_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test score:', score_lstm_elu_FC)\n",
    "print('Test accuracy:', acc_lstm_elu_FC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, None, 32)          787584    \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 30)                7560      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 31        \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 2         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 795,179\n",
      "Trainable params: 795,179\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 218956 samples, validate on 93839 samples\n",
      "Epoch 1/5\n",
      "218956/218956 [==============================] - 147s - loss: 0.5697 - acc: 0.7886 - val_loss: 0.5240 - val_acc: 0.7850\n",
      "Epoch 2/5\n",
      "218956/218956 [==============================] - 144s - loss: 0.5165 - acc: 0.7886 - val_loss: 0.5206 - val_acc: 0.7850\n",
      "Epoch 3/5\n",
      "218956/218956 [==============================] - 145s - loss: 0.5158 - acc: 0.7886 - val_loss: 0.5206 - val_acc: 0.7850\n",
      "Epoch 4/5\n",
      "218956/218956 [==============================] - 145s - loss: 0.5158 - acc: 0.7886 - val_loss: 0.5206 - val_acc: 0.7850\n",
      "Epoch 5/5\n",
      "218956/218956 [==============================] - 144s - loss: 0.5158 - acc: 0.7886 - val_loss: 0.5206 - val_acc: 0.7850\n",
      "93839/93839 [==============================] - 15s    \n",
      "Test score: 0.5205937784398692\n",
      "Test accuracy: 0.7850041027749446\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 32))\n",
    "model.add(LSTM(30, dropout=0.2, recurrent_dropout=0.2))\n",
    "#model.add(LSTM(32, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "print('Train...')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(x_test, y_test))\n",
    "score_lstm_3FC_02dropout, acc_lstm_3FC_02dropout = model.evaluate(x_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test score:', score_lstm_3FC_02dropout)\n",
    "print('Test accuracy:', acc_lstm_3FC_02dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, None, 32)          787584    \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 30)                7560      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 31        \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 2         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 795,179\n",
      "Trainable params: 795,179\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 218956 samples, validate on 93839 samples\n",
      "Epoch 1/5\n",
      "218956/218956 [==============================] - 148s - loss: 0.5695 - acc: 0.7881 - val_loss: 0.5240 - val_acc: 0.7850\n",
      "Epoch 2/5\n",
      "218956/218956 [==============================] - 145s - loss: 0.5166 - acc: 0.7886 - val_loss: 0.5205 - val_acc: 0.7850\n",
      "Epoch 3/5\n",
      "218956/218956 [==============================] - 145s - loss: 0.5158 - acc: 0.7886 - val_loss: 0.5206 - val_acc: 0.7850\n",
      "Epoch 4/5\n",
      "218956/218956 [==============================] - 145s - loss: 0.5158 - acc: 0.7886 - val_loss: 0.5205 - val_acc: 0.7850\n",
      "Epoch 5/5\n",
      "218956/218956 [==============================] - 145s - loss: 0.5158 - acc: 0.7886 - val_loss: 0.5205 - val_acc: 0.7850\n",
      "93839/93839 [==============================] - 15s    \n",
      "Test score: 0.5205205857380903\n",
      "Test accuracy: 0.7850041027749446\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 32))\n",
    "model.add(LSTM(30, dropout=0.8, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "print('Train...')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs= epochs,\n",
    "          validation_data=(x_test, y_test))\n",
    "score_lstm_3FC, acc_lstm_3FC = model.evaluate(x_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test score:', score_lstm_3FC)\n",
    "print('Test accuracy:', acc_lstm_3FC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, None, 32)          787584    \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 30)                7560      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 31        \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 1)                 4         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 2         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 1)                 4         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 2         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 1)                 4         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 795,193\n",
      "Trainable params: 795,187\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 218956 samples, validate on 93839 samples\n",
      "Epoch 1/5\n",
      "218956/218956 [==============================] - 154s - loss: 0.4444 - acc: 0.8460 - val_loss: 0.4198 - val_acc: 0.8462\n",
      "Epoch 2/5\n",
      "218956/218956 [==============================] - 151s - loss: 0.4144 - acc: 0.8497 - val_loss: 0.4193 - val_acc: 0.8462\n",
      "Epoch 3/5\n",
      "218956/218956 [==============================] - 151s - loss: 0.4141 - acc: 0.8498 - val_loss: 0.4204 - val_acc: 0.8462\n",
      "Epoch 4/5\n",
      "218956/218956 [==============================] - 152s - loss: 0.4143 - acc: 0.8498 - val_loss: 0.4203 - val_acc: 0.8462\n",
      "Epoch 5/5\n",
      "218956/218956 [==============================] - 153s - loss: 0.4142 - acc: 0.8498 - val_loss: 0.4206 - val_acc: 0.8462\n",
      "93696/93839 [============================>.] - ETA: 0sTest score: 0.42057135488680075\n",
      "Test accuracy: 0.8461727000526265\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 32))\n",
    "model.add(LSTM(30, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(Dense(1, activation='relu'))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(Dense(1, activation='relu'))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "print('Train...')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs = epochs,\n",
    "          validation_data=(x_test, y_test))\n",
    "score_lstm_3FC_bn, acc_lstm_3FC_bn = model.evaluate(x_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test score:', score_lstm_3FC_bn)\n",
    "print('Test accuracy:', acc_lstm_3FC_bn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_9 (Embedding)      (None, None, 32)          787584    \n",
      "_________________________________________________________________\n",
      "gru_3 (GRU)                  (None, 30)                5670      \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 31        \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 1)                 4         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 2         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 1)                 4         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 2         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 1)                 4         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 793,303\n",
      "Trainable params: 793,297\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 218956 samples, validate on 93839 samples\n",
      "Epoch 1/5\n",
      "218956/218956 [==============================] - 131s - loss: 0.2957 - acc: 0.9071 - val_loss: 0.1736 - val_acc: 0.9539\n",
      "Epoch 2/5\n",
      "218956/218956 [==============================] - 129s - loss: 0.1632 - acc: 0.9588 - val_loss: 0.1590 - val_acc: 0.9604\n",
      "Epoch 3/5\n",
      "218956/218956 [==============================] - 129s - loss: 0.1540 - acc: 0.9620 - val_loss: 0.1562 - val_acc: 0.9611\n",
      "Epoch 4/5\n",
      "218956/218956 [==============================] - 129s - loss: 0.1514 - acc: 0.9630 - val_loss: 0.1550 - val_acc: 0.9617\n",
      "Epoch 5/5\n",
      "218956/218956 [==============================] - 129s - loss: 0.1493 - acc: 0.9637 - val_loss: 0.1534 - val_acc: 0.9622\n",
      "93696/93839 [============================>.] - ETA: 0sTest score: 0.15343637391924858\n",
      "Test accuracy: 0.962190560427967\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 32))\n",
    "model.add(keras.layers.GRU(30, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(Dense(1, activation='relu'))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(Dense(1, activation='relu'))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "print('Train...')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs = epochs,\n",
    "          validation_data=(x_test, y_test))\n",
    "score_gru_3FC_bn, acc_gru_3FC_bn = model.evaluate(x_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test score:', score_gru_3FC_bn)\n",
    "print('Test accuracy:', acc_gru_3FC_bn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM with sigmoid FC  =  0.9622225300781125 \n",
      "\n",
      "GRU with sigmoid FC  =  0.9615618239751063 \n",
      "\n",
      "LSTM with tanh FC  =  0.952983301186074 \n",
      "\n",
      "LSTM with relu FC  =  0.810142904338691 \n",
      "\n",
      "LSTM with elu FC  =  0.8323404980903252 \n",
      "\n",
      "Denser LSTM with 0.2 dropout  =  0.7850041027749446 \n",
      "\n",
      "Denser LSTM with 0.8 dropout  =  0.7850041027749446 \n",
      "\n",
      "Denser LSTM with 0.2 dropout and batchnorm  =  0.8461727000526265 \n",
      "\n",
      "Denser GRU with 0.2 dropout and batchnorm  =  0.962190560427967 \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x190701b8ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken for running the notebook:\n",
      " 1.0 hours, 54.0 minutes and 54.79734396934509 seconds\n"
     ]
    }
   ],
   "source": [
    "#acc_gru_3FC_bn = 0.966\n",
    "names = ['LSTM with sigmoid FC',\n",
    "         'GRU with sigmoid FC',\n",
    "         'LSTM with tanh FC',\n",
    "         'LSTM with relu FC', \n",
    "         'LSTM with elu FC',\n",
    "         'Denser LSTM with 0.2 dropout',\n",
    "         'Denser LSTM with 0.8 dropout',\n",
    "         'Denser LSTM with 0.2 dropout and batchnorm',\n",
    "        'Denser GRU with 0.2 dropout and batchnorm']\n",
    "accs = [acc_lstm_sigmoid_FC,\n",
    "        acc_gru_sigmoid_FC,\n",
    "        acc_lstm_tanh_FC,\n",
    "        acc_lstm_relu_FC,\n",
    "        acc_lstm_elu_FC,\n",
    "        acc_lstm_3FC_02dropout,\n",
    "        acc_lstm_3FC,\n",
    "        acc_lstm_3FC_bn,\n",
    "       acc_gru_3FC_bn]\n",
    "for i in range(len(names)):\n",
    "    print(names[i],\" = \", accs[i],\"\\n\" )\n",
    "x = [i for i in range(len(names))]\n",
    "plt.figure(figsize=(12,8))\n",
    "pl.xticks(x, names)\n",
    "pl.xticks(range(len(names)), names, rotation=60) #writes strings with 45 degree angle\n",
    "pl.plot(x,accs,'*')\n",
    "pl.show()\n",
    "end = time.time()\n",
    "seconds = end - start\n",
    "minutes = seconds//60\n",
    "seconds = seconds % 60\n",
    "hours = 0\n",
    "if minutes > 60:\n",
    "    hours = minutes//60\n",
    "    minutes = minutes%60\n",
    "print(\"time taken for running the notebook:\\n {0} hours, {1} minutes and {2} seconds\".format(hours,minutes,seconds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Train...\n",
      "Train on 218956 samples, validate on 93839 samples\n",
      "Epoch 1/5\n",
      "218956/218956 [==============================] - 148s - loss: 0.2430 - acc: 0.9210 - val_loss: 0.1471 - val_acc: 0.9602\n",
      "Epoch 2/5\n",
      "218956/218956 [==============================] - 146s - loss: 0.1405 - acc: 0.9620 - val_loss: 0.1413 - val_acc: 0.9620\n",
      "Epoch 3/5\n",
      "218956/218956 [==============================] - 144s - loss: 0.1304 - acc: 0.9641 - val_loss: 0.1440 - val_acc: 0.9619\n",
      "Epoch 4/5\n",
      "218956/218956 [==============================] - 144s - loss: 0.1253 - acc: 0.9647 - val_loss: 0.1479 - val_acc: 0.9618\n",
      "Epoch 5/5\n",
      "218956/218956 [==============================] - 145s - loss: 0.1221 - acc: 0.9650 - val_loss: 0.1513 - val_acc: 0.9616\n",
      "93696/93839 [============================>.] - ETA: 0sTest score: 0.15129417664343234\n",
      "Test accuracy: 0.9616044501753003\n",
      "Build model...\n",
      "Train...\n",
      "Train on 218956 samples, validate on 93839 samples\n",
      "Epoch 1/5\n",
      "218956/218956 [==============================] - 147s - loss: 0.3076 - acc: 0.8938 - val_loss: 0.1874 - val_acc: 0.9477\n",
      "Epoch 2/5\n",
      "218956/218956 [==============================] - 144s - loss: 0.1771 - acc: 0.9496 - val_loss: 0.1538 - val_acc: 0.9584\n",
      "Epoch 3/5\n",
      "218956/218956 [==============================] - 144s - loss: 0.1524 - acc: 0.9577 - val_loss: 0.1509 - val_acc: 0.9602\n",
      "Epoch 4/5\n",
      "218956/218956 [==============================] - 144s - loss: 0.1418 - acc: 0.9603 - val_loss: 0.1531 - val_acc: 0.9601\n",
      "Epoch 5/5\n",
      "218956/218956 [==============================] - 145s - loss: 0.1361 - acc: 0.9615 - val_loss: 0.1551 - val_acc: 0.9607\n",
      "93696/93839 [============================>.] - ETA: 0sTest score: 0.1550604185819787\n",
      "Test accuracy: 0.9607199565212758\n"
     ]
    }
   ],
   "source": [
    "### search for hyperparameters ###\n",
    "\n",
    "### IN THIS BLOCK ###\n",
    "\n",
    "## TO CHECK: RECURRENT DROPOUT RATE ##\n",
    "\n",
    "# CHECK 0.2, 0.8 #\n",
    "\n",
    "\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 32))\n",
    "model.add(LSTM(30, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "print('Train...')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(x_test, y_test))\n",
    "score_lstm_sigmoid_FC, acc_lstm_sigmoid_FC = model.evaluate(x_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test score:', score_lstm_sigmoid_FC)\n",
    "print('Test accuracy:', acc_lstm_sigmoid_FC)\n",
    "print('Build model...')\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 32))\n",
    "model.add(LSTM(30, dropout=0.2, recurrent_dropout=0.8))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "print('Train...')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(x_test, y_test))\n",
    "score_lstm_sigmoid_FC, acc_lstm_sigmoid_FC = model.evaluate(x_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test score:', score_lstm_sigmoid_FC)\n",
    "print('Test accuracy:', acc_lstm_sigmoid_FC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Train...\n",
      "Train on 218956 samples, validate on 93839 samples\n",
      "Epoch 1/5\n",
      "218956/218956 [==============================] - 167s - loss: 0.2306 - acc: 0.9260 - val_loss: 0.1465 - val_acc: 0.9606\n",
      "Epoch 2/5\n",
      "218956/218956 [==============================] - 164s - loss: 0.1375 - acc: 0.9630 - val_loss: 0.1400 - val_acc: 0.9623\n",
      "Epoch 3/5\n",
      "218956/218956 [==============================] - 164s - loss: 0.1290 - acc: 0.9645 - val_loss: 0.1437 - val_acc: 0.9621\n",
      "Epoch 4/5\n",
      "218956/218956 [==============================] - 164s - loss: 0.1240 - acc: 0.9651 - val_loss: 0.1462 - val_acc: 0.9622\n",
      "Epoch 5/5\n",
      "218956/218956 [==============================] - 164s - loss: 0.1203 - acc: 0.9656 - val_loss: 0.1508 - val_acc: 0.9621\n",
      "93839/93839 [==============================] - 17s    \n",
      "Test score: 0.15075726445648502\n",
      "Test accuracy: 0.9621159645776276\n",
      "Build model...\n"
     ]
    }
   ],
   "source": [
    "### search for hyperparameters ###\n",
    "\n",
    "### IN THIS BLOCK ###\n",
    "\n",
    "## TO CHECK: number of LSTM units ##\n",
    "# already have: 128 in github. 30 in this notebook #\n",
    "# CHECK 64 #\n",
    "\n",
    "\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 32))\n",
    "model.add(LSTM(64, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "print('Train...')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(x_test, y_test))\n",
    "score_lstm_sigmoid_FC, acc_lstm_sigmoid_FC = model.evaluate(x_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test score:', score_lstm_sigmoid_FC)\n",
    "print('Test accuracy:', acc_lstm_sigmoid_FC)\n",
    "print('Build model...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'dict'> <class 'dict'> <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "if os.name != 'posix':\n",
    "    final_embeddings = pickle.load(open(r'M:\\Course stuff\\ASPRI\\supervised\\loal_FE','rb'))\n",
    "    dictionary = pickle.load(open(r'M:\\Course stuff\\ASPRI\\supervised\\dictionary','rb'))\n",
    "    reverse_dictionary = pickle.load(open(r'M:\\Course stuff\\ASPRI\\supervised\\reverse_dictionary','rb'))\n",
    "    count = pickle.load(open(r'M:\\Course stuff\\ASPRI\\supervised\\count','rb'))\n",
    "else:\n",
    "    final_embeddings = pickle.load(open('loal_FE','rb'))\n",
    "    dictionary = pickle.load(open('dictionary','rb'))\n",
    "    reverse_dictionary = pickle.load(open('reverse_dictionary','rb'))\n",
    "    count = pickle.load(open('count','rb'))\n",
    "print(type(final_embeddings),type(dictionary),type(reverse_dictionary),type(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6338, 9583, 16843, 16843]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24617"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_ = dictionary.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dictionary['UNK']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24616"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'51218'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverse_dictionary[6338]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = {}\n",
    "for i in list(reverse_dictionary.keys()):\n",
    "    embedding_matrix[i] = final_embeddings[i-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24616, 32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(dictionary), 32))\n",
    "for i in list(reverse_dictionary.keys()):\n",
    "    embedding_vector = final_embeddings[i-1]#.reshape((32,1))\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i-1] = embedding_vector    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24616"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00509059, -0.1217261 ,  0.09797727, -0.12125774,  0.12365056,\n",
       "        0.1939962 ,  0.15530343,  0.16010445, -0.05775205,  0.01387483,\n",
       "        0.01254192,  0.13052085, -0.08905942,  0.10333601, -0.2506293 ,\n",
       "        0.26715744,  0.24938019,  0.03133765,  0.30514485, -0.23772131,\n",
       "       -0.03991247,  0.29453826, -0.19590616,  0.33119026,  0.07087544,\n",
       "       -0.28860688,  0.05331763,  0.11969152,  0.21679501, -0.25569105,\n",
       "        0.11104064, -0.07249188], dtype=float32)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_embeddings[6338]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00509059, -0.1217261 ,  0.09797727, -0.12125774,  0.12365056,\n",
       "        0.19399621,  0.15530343,  0.16010445, -0.05775205,  0.01387483,\n",
       "        0.01254192,  0.13052085, -0.08905942,  0.10333601, -0.25062931,\n",
       "        0.26715744,  0.24938019,  0.03133765,  0.30514485, -0.23772131,\n",
       "       -0.03991247,  0.29453826, -0.19590616,  0.33119026,  0.07087544,\n",
       "       -0.28860688,  0.05331763,  0.11969152,  0.21679501, -0.25569105,\n",
       "        0.11104064, -0.07249188])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[6338]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_23 (Embedding)     (None, None, 32)          787712    \n",
      "_________________________________________________________________\n",
      "lstm_14 (LSTM)               (None, 30)                7560      \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 795,303\n",
      "Trainable params: 7,591\n",
      "Non-trainable params: 787,712\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 218956 samples, validate on 93839 samples\n",
      "Epoch 1/5\n",
      "218956/218956 [==============================] - 144s - loss: 0.3975 - acc: 0.8567 - val_loss: 0.3118 - val_acc: 0.8968\n",
      "Epoch 2/5\n",
      "218956/218956 [==============================] - 144s - loss: 0.2899 - acc: 0.9038 - val_loss: 0.2498 - val_acc: 0.9207\n",
      "Epoch 3/5\n",
      "218956/218956 [==============================] - 125s - loss: 0.2546 - acc: 0.9178 - val_loss: 0.2326 - val_acc: 0.9274\n",
      "Epoch 4/5\n",
      "218956/218956 [==============================] - 125s - loss: 0.2375 - acc: 0.9254 - val_loss: 0.2191 - val_acc: 0.9337\n",
      "Epoch 5/5\n",
      "218956/218956 [==============================] - 125s - loss: 0.2272 - acc: 0.9307 - val_loss: 0.2121 - val_acc: 0.9355\n",
      "93824/93839 [============================>.] - ETA: 0sTest score: 0.21212848076096116\n",
      "Test accuracy: 0.9355385287567003\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(embedding_matrix), 32,weights = [embedding_matrix],trainable = False))\n",
    "model.add(LSTM(30, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "print('Train...')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(x_test, y_test))\n",
    "score_lstm_sigmoid_FC, acc_lstm_sigmoid_FC = model.evaluate(x_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test score:', score_lstm_sigmoid_FC)\n",
    "print('Test accuracy:', acc_lstm_sigmoid_FC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building w2v embedding model with denser (16 units) FC layer ...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_40 (Embedding)     (None, None, 32)          787712    \n",
      "_________________________________________________________________\n",
      "lstm_31 (LSTM)               (None, 30)                7560      \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 16)                496       \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 795,785\n",
      "Trainable params: 8,073\n",
      "Non-trainable params: 787,712\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 218956 samples, validate on 93839 samples\n",
      "Epoch 1/5\n",
      "218956/218956 [==============================] - 130s - loss: 0.4587 - acc: 0.8187 - val_loss: 0.3888 - val_acc: 0.8656\n",
      "Epoch 2/5\n",
      "218956/218956 [==============================] - 131s - loss: 0.3855 - acc: 0.8647 - val_loss: 0.3780 - val_acc: 0.8683\n",
      "Epoch 3/5\n",
      "218956/218956 [==============================] - 128s - loss: 0.3665 - acc: 0.8689 - val_loss: 0.3277 - val_acc: 0.8738\n",
      "Epoch 4/5\n",
      "218956/218956 [==============================] - 132s - loss: 0.3057 - acc: 0.8902 - val_loss: 0.2679 - val_acc: 0.9113\n",
      "Epoch 5/5\n",
      "218956/218956 [==============================] - 143s - loss: 0.2763 - acc: 0.9066 - val_loss: 0.2498 - val_acc: 0.9193\n",
      "93824/93839 [============================>.] - ETA: 0sTest score: 0.24983315115868598\n",
      "Test accuracy: 0.9193299161335863\n"
     ]
    }
   ],
   "source": [
    "#from keras.layers import TimeDistributed\n",
    "print('Building w2v embedding model with denser (16 units) FC layer ...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(embedding_matrix), 32,weights = [embedding_matrix],trainable = False))\n",
    "model.add(LSTM(30, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(16, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "print('Train...')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(x_test, y_test))\n",
    "score_lstm_sigmoid_FC, acc_lstm_sigmoid_FC = model.evaluate(x_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test score:', score_lstm_sigmoid_FC)\n",
    "print('Test accuracy:', acc_lstm_sigmoid_FC)\n",
    "## Adding a FC layer did not help but hurt both in terms of training and validation accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Trainable w2v embedding model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_24 (Embedding)     (None, None, 32)          787712    \n",
      "_________________________________________________________________\n",
      "lstm_15 (LSTM)               (None, 30)                7560      \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 795,303\n",
      "Trainable params: 795,303\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 218956 samples, validate on 93839 samples\n",
      "Epoch 1/5\n",
      "218956/218956 [==============================] - 153s - loss: 0.2384 - acc: 0.9250 - val_loss: 0.1498 - val_acc: 0.9599\n",
      "Epoch 2/5\n",
      "218956/218956 [==============================] - 156s - loss: 0.1427 - acc: 0.9617 - val_loss: 0.1421 - val_acc: 0.9619\n",
      "Epoch 3/5\n",
      "218956/218956 [==============================] - 158s - loss: 0.1329 - acc: 0.9637 - val_loss: 0.1421 - val_acc: 0.9622\n",
      "Epoch 4/5\n",
      "218956/218956 [==============================] - 156s - loss: 0.1276 - acc: 0.9645 - val_loss: 0.1473 - val_acc: 0.9614\n",
      "Epoch 5/5\n",
      "218956/218956 [==============================] - 159s - loss: 0.1235 - acc: 0.9650 - val_loss: 0.1496 - val_acc: 0.9619\n",
      "93839/93839 [==============================] - 16s    \n",
      "Test score: 0.14956105557707242\n",
      "Test accuracy: 0.9619454597768519\n"
     ]
    }
   ],
   "source": [
    "print('Building Trainable w2v embedding model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(embedding_matrix), 32,weights = [embedding_matrix],trainable = True))\n",
    "model.add(LSTM(30, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "print('Train...')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(x_test, y_test))\n",
    "score_lstm_sigmoid_FC, acc_lstm_sigmoid_FC = model.evaluate(x_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test score:', score_lstm_sigmoid_FC)\n",
    "print('Test accuracy:', acc_lstm_sigmoid_FC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building w2v embedding model with denser (16 units) FC layer ...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_41 (Embedding)     (None, None, 32)          787712    \n",
      "_________________________________________________________________\n",
      "lstm_32 (LSTM)               (None, 30)                7560      \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 32)                992       \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 796,297\n",
      "Trainable params: 8,585\n",
      "Non-trainable params: 787,712\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 218956 samples, validate on 93839 samples\n",
      "Epoch 1/5\n",
      "218956/218956 [==============================] - 176s - loss: 0.3905 - acc: 0.8530 - val_loss: 0.2856 - val_acc: 0.9030\n",
      "Epoch 2/5\n",
      "218956/218956 [==============================] - 171s - loss: 0.2766 - acc: 0.9073 - val_loss: 0.2441 - val_acc: 0.9212\n",
      "Epoch 3/5\n",
      "218956/218956 [==============================] - 144s - loss: 0.2481 - acc: 0.9196 - val_loss: 0.2243 - val_acc: 0.9310\n",
      "Epoch 4/5\n",
      "218956/218956 [==============================] - 147s - loss: 0.2306 - acc: 0.9275 - val_loss: 0.2172 - val_acc: 0.9333\n",
      "Epoch 5/5\n",
      "218956/218956 [==============================] - 179s - loss: 0.2205 - acc: 0.9325 - val_loss: 0.2042 - val_acc: 0.9398\n",
      "93839/93839 [==============================] - 20s    \n",
      "Test score: 0.20420227030422147\n",
      "Test accuracy: 0.9397585225759013\n"
     ]
    }
   ],
   "source": [
    "print('Building w2v embedding model with denser (16 units) FC layer ...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(embedding_matrix), 32,weights = [embedding_matrix],trainable = False))\n",
    "model.add(LSTM(30, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(32, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "print('Train...')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(x_test, y_test))\n",
    "score_lstm_sigmoid_FC, acc_lstm_sigmoid_FC = model.evaluate(x_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test score:', score_lstm_sigmoid_FC)\n",
    "print('Test accuracy:', acc_lstm_sigmoid_FC)\n",
    "# increasing number of hidden units in dense layer helped\n",
    "# ==>> extra layer with more hidden units\n",
    "\n",
    "# try lstm : 128 -> Dense : 64 -> Dens: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building w2v embedding model with denser (16 units) FC layer and 128 hidden units in LSTM ...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_42 (Embedding)     (None, None, 32)          787712    \n",
      "_________________________________________________________________\n",
      "lstm_33 (LSTM)               (None, 128)               82432     \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 16)                2064      \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 872,225\n",
      "Trainable params: 84,513\n",
      "Non-trainable params: 787,712\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 218956 samples, validate on 93839 samples\n",
      "Epoch 1/5\n",
      "218956/218956 [==============================] - 214s - loss: 0.3395 - acc: 0.8821 - val_loss: 0.2509 - val_acc: 0.9187\n",
      "Epoch 2/5\n",
      "218956/218956 [==============================] - 228s - loss: 0.2401 - acc: 0.9229 - val_loss: 0.2173 - val_acc: 0.9335\n",
      "Epoch 3/5\n",
      "218956/218956 [==============================] - 224s - loss: 0.2145 - acc: 0.9342 - val_loss: 0.2038 - val_acc: 0.9385\n",
      "Epoch 4/5\n",
      "218956/218956 [==============================] - 233s - loss: 0.2013 - acc: 0.9398 - val_loss: 0.1911 - val_acc: 0.9439\n",
      "Epoch 5/5\n",
      "218956/218956 [==============================] - 233s - loss: 0.1929 - acc: 0.9430 - val_loss: 0.1920 - val_acc: 0.9442\n",
      "93824/93839 [============================>.] - ETA: 0sTest score: 0.19199804229045042\n",
      "Test accuracy: 0.9442449301463144\n"
     ]
    }
   ],
   "source": [
    "print('Building w2v embedding model with denser (16 units) FC layer and 128 hidden units in LSTM ...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(embedding_matrix), 32,weights = [embedding_matrix],trainable = False))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(16, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "print('Train...')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(x_test, y_test))\n",
    "score_lstm_sigmoid_FC, acc_lstm_sigmoid_FC = model.evaluate(x_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test score:', score_lstm_sigmoid_FC)\n",
    "print('Test accuracy:', acc_lstm_sigmoid_FC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building w2v embedding model with denser (32 units) FC layer and 128 hidden units in LSTM ...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_43 (Embedding)     (None, None, 32)          787712    \n",
      "_________________________________________________________________\n",
      "lstm_34 (LSTM)               (None, 128)               82432     \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 874,305\n",
      "Trainable params: 86,593\n",
      "Non-trainable params: 787,712\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 218956 samples, validate on 93839 samples\n",
      "Epoch 1/5\n",
      "218956/218956 [==============================] - 234s - loss: 0.3483 - acc: 0.8753 - val_loss: 0.2528 - val_acc: 0.9185\n",
      "Epoch 2/5\n",
      "218956/218956 [==============================] - 189s - loss: 0.2456 - acc: 0.9200 - val_loss: 0.2225 - val_acc: 0.9313\n",
      "Epoch 3/5\n",
      "218956/218956 [==============================] - 186s - loss: 0.2203 - acc: 0.9321 - val_loss: 0.2057 - val_acc: 0.9388\n",
      "Epoch 4/5\n",
      "218956/218956 [==============================] - 185s - loss: 0.2066 - acc: 0.9382 - val_loss: 0.1969 - val_acc: 0.9425\n",
      "Epoch 5/5\n",
      "218956/218956 [==============================] - 185s - loss: 0.1977 - acc: 0.9417 - val_loss: 0.1891 - val_acc: 0.9448\n",
      "93824/93839 [============================>.] - ETA: 0sTest score: 0.18911368829196404\n",
      "Test accuracy: 0.9448097272988842\n"
     ]
    }
   ],
   "source": [
    "print('Building w2v embedding model with denser (32 units) FC layer and 128 hidden units in LSTM ...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(embedding_matrix), 32,weights = [embedding_matrix],trainable = False))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(32, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "print('Train...')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(x_test, y_test))\n",
    "score_lstm_sigmoid_FC, acc_lstm_sigmoid_FC = model.evaluate(x_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test score:', score_lstm_sigmoid_FC)\n",
    "print('Test accuracy:', acc_lstm_sigmoid_FC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix_ = embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building trainable w2v embedding model with denser (32 units) FC layer and 128 hidden units in LSTM ...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_44 (Embedding)     (None, None, 32)          787712    \n",
      "_________________________________________________________________\n",
      "lstm_35 (LSTM)               (None, 128)               82432     \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 874,305\n",
      "Trainable params: 874,305\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 218956 samples, validate on 93839 samples\n",
      "Epoch 1/5\n",
      "218956/218956 [==============================] - 206s - loss: 0.2278 - acc: 0.9262 - val_loss: 0.1482 - val_acc: 0.9608\n",
      "Epoch 2/5\n",
      "218956/218956 [==============================] - 202s - loss: 0.1409 - acc: 0.9627 - val_loss: 0.1439 - val_acc: 0.9612\n",
      "Epoch 3/5\n",
      "218956/218956 [==============================] - 203s - loss: 0.1330 - acc: 0.9640 - val_loss: 0.1404 - val_acc: 0.9625\n",
      "Epoch 4/5\n",
      "218956/218956 [==============================] - 202s - loss: 0.1274 - acc: 0.9648 - val_loss: 0.1425 - val_acc: 0.9629\n",
      "Epoch 5/5\n",
      "218956/218956 [==============================] - 202s - loss: 0.1231 - acc: 0.9653 - val_loss: 0.1497 - val_acc: 0.9619\n",
      "93824/93839 [============================>.] - ETA: 0sTest score: 0.14974221508381072\n",
      "Test accuracy: 0.9619241466767549\n"
     ]
    }
   ],
   "source": [
    "print('Building trainable w2v embedding model with denser (32 units) FC layer and 128 hidden units in LSTM ...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(embedding_matrix), 32,weights = [embedding_matrix],trainable = True))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(32, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "print('Train...')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(x_test, y_test))\n",
    "score_lstm_sigmoid_FC, acc_lstm_sigmoid_FC = model.evaluate(x_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test score:', score_lstm_sigmoid_FC)\n",
    "print('Test accuracy:', acc_lstm_sigmoid_FC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building trainable w2v embedding model with denser (64 units) FC layer and 128 hidden units in LSTM ...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_45 (Embedding)     (None, None, 32)          787712    \n",
      "_________________________________________________________________\n",
      "lstm_36 (LSTM)               (None, 128)               82432     \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 878,465\n",
      "Trainable params: 878,465\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 218956 samples, validate on 93839 samples\n",
      "Epoch 1/5\n",
      "218956/218956 [==============================] - 208s - loss: 0.2066 - acc: 0.9361 - val_loss: 0.1449 - val_acc: 0.9609\n",
      "Epoch 2/5\n",
      "218956/218956 [==============================] - 203s - loss: 0.1385 - acc: 0.9629 - val_loss: 0.1392 - val_acc: 0.9625\n",
      "Epoch 3/5\n",
      "218956/218956 [==============================] - 204s - loss: 0.1307 - acc: 0.9642 - val_loss: 0.1398 - val_acc: 0.9627964\n",
      "Epoch 4/5\n",
      "218956/218956 [==============================] - 203s - loss: 0.1251 - acc: 0.9651 - val_loss: 0.1443 - val_acc: 0.9625\n",
      "Epoch 5/5\n",
      "218956/218956 [==============================] - 203s - loss: 0.1214 - acc: 0.9654 - val_loss: 0.1512 - val_acc: 0.9626\n",
      "93839/93839 [==============================] - 25s    \n",
      "Test score: 0.15116789425131852\n",
      "Test accuracy: 0.962648792080052\n"
     ]
    }
   ],
   "source": [
    "print('Building trainable w2v embedding model with denser (64 units) FC layer and 128 hidden units in LSTM ...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(embedding_matrix), 32,weights = [embedding_matrix],trainable = True))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(64, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "print('Train...')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(x_test, y_test))\n",
    "score_lstm_sigmoid_FC, acc_lstm_sigmoid_FC = model.evaluate(x_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test score:', score_lstm_sigmoid_FC)\n",
    "print('Test accuracy:', acc_lstm_sigmoid_FC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building trainable w2v embedding model with extra units for last model ...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_46 (Embedding)     (None, None, 32)          787712    \n",
      "_________________________________________________________________\n",
      "lstm_37 (LSTM)               (None, 128)               82432     \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 880,513\n",
      "Trainable params: 880,513\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 218956 samples, validate on 93839 samples\n",
      "Epoch 1/5\n",
      "218956/218956 [==============================] - 208s - loss: 0.2059 - acc: 0.9376 - val_loss: 0.1478 - val_acc: 0.9610\n",
      "Epoch 2/5\n",
      "218956/218956 [==============================] - 204s - loss: 0.1393 - acc: 0.9628 - val_loss: 0.1393 - val_acc: 0.9623\n",
      "Epoch 3/5\n",
      "218956/218956 [==============================] - 203s - loss: 0.1315 - acc: 0.9644 - val_loss: 0.1399 - val_acc: 0.9629\n",
      "Epoch 4/5\n",
      "218956/218956 [==============================] - 204s - loss: 0.1261 - acc: 0.9651 - val_loss: 0.1422 - val_acc: 0.9628\n",
      "Epoch 5/5\n",
      "218956/218956 [==============================] - 204s - loss: 0.1221 - acc: 0.9654 - val_loss: 0.1448 - val_acc: 0.9631\n",
      "93824/93839 [============================>.] - ETA: 0sTest score: 0.1448456367787643\n",
      "Test accuracy: 0.96308571063204\n"
     ]
    }
   ],
   "source": [
    "print('Building trainable w2v embedding model with extra units for last model ...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(embedding_matrix), 32,weights = [embedding_matrix],trainable = True))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(64, activation='sigmoid'))\n",
    "model.add(Dense(32, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "print('Train...')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(x_test, y_test))\n",
    "score_lstm_sigmoid_FC, acc_lstm_sigmoid_FC = model.evaluate(x_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test score:', score_lstm_sigmoid_FC)\n",
    "print('Test accuracy:', acc_lstm_sigmoid_FC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
